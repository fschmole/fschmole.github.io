[ { "title": "From Formal Model to Sequence Diagram: TLA+ as a Machine-Readable Specification", "url": "/2026/02/22/tlaplus-sequence-diagrams/", "categories": "Architecture", "tags": "tla+, pluscal, formal-methods, verification, visualization, vscode", "date": "2026-02-22 18:00:00 -0800", "content": "In a previous post I argued that machine-readable specifications are the foundation for AI-augmented hardware design. This post digs into a specific tool for that job: TLA+ and its procedural front-end PlusCal. What TLA+ Brings to Hardware Architecture TLA+ (Temporal Logic of Actions) is a formal specification language for describing concurrent and distributed systems. PlusCal is a pseudocode-like layer that compiles down to TLA+, making it accessible to engineers who are more comfortable with imperative algorithms than with temporal logic. The key properties that make TLA+/PlusCal valuable for fabric and protocol architecture: Exhaustive model checking. The TLC model checker explores every reachable state of the specification, proving invariants (e.g. no deadlock, mutual exclusion, ordering guarantees) or producing a concrete counter-example trace when a property is violated. Deadlock analysis. TLC can detect deadlocked states — situations where the system has not terminated but no process can take a step. For a fabric with credit-based flow control, this catches credit leaks and circular dependencies that are nearly impossible to find by inspection. Precise enough for machines, readable enough for humans. A TLA+ spec is simultaneously a mathematical proof artifact and a document that an architect can review for intent. It is also structured enough for an LLM to consume without ambiguity — unlike prose. The Visualization Problem There is a catch. TLC’s output is purely textual. When the model checker finds a counter-example — a sequence of states that violates an invariant or leads to deadlock — the output looks like a wall of nested records: State 1: &lt;Initial predicate&gt; /\\ cache = (p1 :&gt; \"I\" @@ p2 :&gt; \"I\") /\\ bus = &lt;&lt;&gt;&gt; /\\ memory = [addr1 |-&gt; 0] /\\ _seqDiagramTrace = &lt;&lt;&gt;&gt; State 2: p1 issues ReadReq /\\ cache = (p1 :&gt; \"IS_D\" @@ p2 :&gt; \"I\") /\\ bus = &lt;&lt;[msg |-&gt; \"ReadReq\", src |-&gt; \"p1\", dst |-&gt; \"Memory\", ch |-&gt; \"req\"]&gt;&gt; /\\ _seqDiagramTrace = &lt;&lt; [msg |-&gt; \"ReadReq\", src |-&gt; \"p1\", dst |-&gt; \"Memory\", ch |-&gt; \"req\"] &gt;&gt; ... For a protocol architect, the natural visualization of this trace is a sequence diagram — it immediately shows who sent what, to whom, and in what order. But drawing sequence diagrams by hand is exactly the kind of busywork that slows down the specification process: Architects spend hours in Visio drawing message flows that are already fully described by the formal model. Diagrams are out of date the moment they are published — the model evolves, but nobody updates the Visio file. It is nearly impossible to draw all combinations manually. A four-processor MESI protocol has hundreds of interesting interleavings. No one is going to draw each one by hand. Generating Sequence Diagrams from TLC Traces To close this gap, I contributed an enhancement to the TLA+ VS Code extension that automatically generates PlantUML sequence diagrams from TLC model-checking traces. How It Works The flow is fully automatic — no commands to invoke, no buttons to click: flowchart LR A[\"TLA+ / PlusCal&lt;br/&gt;Specification\"] --&gt; B[\"TLC&lt;br/&gt;Model Checker\"] B --&gt; C[\"Trace Output&lt;br/&gt;(textual states)\"] C --&gt; D[\"Trace Parser\"] D --&gt; E[\"PlantUML&lt;br/&gt;Generator\"] E --&gt; F[\".puml File&lt;br/&gt;(opens in editor)\"] F --&gt; G[\"PlantUML Renderer&lt;br/&gt;(preview as SVG)\"] The user runs TLC from VS Code as usual. The extension captures TLC’s raw stdout. After TLC completes, a trace parser extracts a designated trace variable (by default _seqDiagramTrace) from the output. This variable is a TLA+ sequence of records, each with msg (message label), src (source participant), dst (destination participant), and an optional ch (channel, for color grouping). A PlantUML generator converts the parsed messages into .puml text — declaring participants in first-appearance order, assigning colors per channel from an 8-color palette, and rendering arrows with autonumbered labels. The generated .puml opens automatically in a side-by-side editor tab, ready for preview with any PlantUML renderer extension. The extension generates PlantUML text, not rendered images. This avoids bundling a 20 MB plantuml.jar and lets users choose their preferred renderer. The contribution is the generation engine. The Trace Variable Convention The only requirement on the TLA+ specification is that it maintain a sequence variable containing the message history. In PlusCal, this typically looks like: _seqDiagramTrace := Append(_seqDiagramTrace, [msg |-&gt; \"ReadReq\", src |-&gt; self, dst |-&gt; \"Memory\", ch |-&gt; \"req\"]); Each record has: Field Required Purpose msg Yes Arrow label (e.g. “ReadReq”, “DataResp”) src Yes Source participant dst Yes Destination participant ch No Channel name — messages on the same channel share a color If ch is omitted, each distinct msg type gets its own color automatically. The variable name is configurable via a VS Code setting. Concurrent Region Detection The most interesting part of the generator is its handling of concurrency. When TLC produces multiple terminal traces (via exhaustive state-space exploration), the generator compares all traces against a canonical first trace to identify: Fixed positions — messages that appear at the same index in every trace. These are sequential steps. Variant regions — contiguous ranges where message order differs across traces. These represent true concurrency. Variant regions are recursively split into independent concurrent chains — subsets whose internal order is stable but whose relative ordering with other subsets varies. The result is rendered using PlantUML’s par / group constructs with distinct colors: par Concurrent Chains group #FF6B6B Chain 1 p1 -&gt; Memory : ReadReq end group #00BBF9 Chain 2 p2 -&gt; Memory : ReadReq end end This means you see not just a trace but the structure of the concurrency — which messages are ordered and which are independent. Color Coding Messages are color-coded by channel (or by message type if no channel is specified) using an 8-color palette — red, blue, green, orange, purple, teal, deep-orange, indigo. When an explicit ch field is present, the channel name is annotated below the arrow label in a smaller font. Concurrent region boxes use a separate 6-color palette. The visual result is that you can instantly distinguish traffic on different channels (request vs. data vs. snoop, for example) without reading every label. Example: Snoopy-Bus MESI Protocol Here is a screenshot of a sequence diagram generated from a TLA+ specification of a textbook snoopy-bus MESI cache-coherence protocol. The model describes processors issuing reads and writes, the bus arbitrating between them, and caches transitioning through Modified, Exclusive, Shared, and Invalid states. Sequence diagram auto-generated from TLC output. Each arrow is a protocol message; colors distinguish channels (request, data, snoop). Autonumbering shows the global message order. This diagram was not drawn by hand. It was generated directly from the TLC model checker’s trace output — the formal model is the documentation. If the model changes, re-running TLC produces an updated diagram automatically. The Iterative Modeling Loop The real payoff is in how this changes the specification workflow: flowchart TD A[\"Write / Edit&lt;br/&gt;PlusCal Spec\"] --&gt; B[\"Run TLC&lt;br/&gt;(Ctrl+Shift+P)\"] B --&gt; C{\"Invariant&lt;br/&gt;Holds?\"} C -- \"Yes\" --&gt; D[\"Spec is Correct&lt;br/&gt;(for this state space)\"] C -- \"No\" --&gt; E[\"Counter-example&lt;br/&gt;Sequence Diagram&lt;br/&gt;Opens Automatically\"] E --&gt; F[\"Inspect Diagram:&lt;br/&gt;Identify Root Cause\"] F --&gt; A D --&gt; G[\"Diagrams Serve as&lt;br/&gt;Auto-Generated&lt;br/&gt;Documentation\"] Without visualization, the loop is: edit spec → run TLC → read 200 lines of textual state → squint → maybe understand the bug → edit spec. With automatic diagram generation, the loop becomes: edit spec → run TLC → look at the picture → see the bug → fix it. The time from “TLC found a violation” to “I understand what went wrong” drops from minutes to seconds. Over the course of a multi-week specification effort, that compounds into days of saved time — and the diagrams are documentation artifacts you keep. Why This Matters for Fabric Architecture A fabric specification involves exactly the kind of multi-agent, message-passing, ordering-sensitive behavior that TLA+ was designed for. The message types are protocol-specific (requests, completions, snoops, credits), the participants are fabric agents (requesters, completers, home agents, snoop filters), and the invariants are the ordering rules and deadlock-freedom properties the fabric must guarantee. By writing the specification in TLA+/PlusCal: The model checker proves properties that simulation would take years to cover. Counter-examples are visualized automatically as sequence diagrams that the entire team can read. The diagrams stay in sync with the model because they are generated from it — not maintained separately. The spec is machine-readable — it can feed directly into AI-augmented RTL generation and testbench synthesis pipelines. Architects no longer have to choose between a formal model (for correctness) and pretty diagrams (for communication). They get both from the same source." }, { "title": "Machine-Readable Specifications: The Single Source of Truth for AI-Augmented Hardware Design", "url": "/2026/02/22/machine-readable-specs-single-source-of-truth/", "categories": "Architecture", "tags": "specifications, tla+, ai, rtl, formal-methods, fabric", "date": "2026-02-22 14:00:00 -0800", "content": "Every hardware team has lived this: a 400-page PDF spec says one thing, the RTL says another, and the testbench assumes a third. The bug that falls out is nobody’s fault and everybody’s problem. Now multiply that failure mode by an LLM that has no judgment about which source to trust — and “making something up” becomes the default behavior whenever the input is ambiguous. If we are serious about AI-augmented hardware design, we need to fix the input before we fix the model. Ease of Consumption — Not Just for Humans Architectural specifications have historically been written for humans. They are prose documents — Word files, Confluence pages, PDFs — optimized for readability by an engineer who already has context. That works (barely) when the consumer is a person who can resolve ambiguity by walking to the next cubicle. It does not work when the consumer is an LLM. Large language models are extremely sensitive to the quality of their input. Give an LLM a clean, unambiguous, machine-readable rule set and it will generate correct RTL, accurate testbench stimulus, and valid configuration sequences. Give it a vague paragraph with an implicit cross-reference to a table four sections away and it will hallucinate plausible-looking logic that is wrong. The problem is not the model. The problem is the specification. The Single Source of Truth The fix is a machine-readable golden source — a structured, formal representation of the design’s rules and behaviors from which everything else is derived. Not “also maintained alongside the PDF,” but the actual source of record. flowchart TD subgraph legacy[\"Legacy Corpus (existing specs)\"] direction TB PDF_OLD[\"PDF Specs\"] WORD_OLD[\"Word / Confluence Docs\"] PG_OLD[\"Programmer's Guides\"] end subgraph conversion[\"Conversion &amp; Verification\"] direction TB LLM_CONVERT[\"LLM-Assisted&lt;br/&gt;Conversion\"] MANUAL_REVIEW[\"Manual Review&lt;br/&gt;&amp; Reconciliation\"] RTL_VERIFY[\"Verify Against&lt;br/&gt;Existing RTL&lt;br/&gt;(true golden ref)\"] end subgraph golden[\"Machine-Readable Golden Source\"] direction TB TLA[\"TLA+ / PlusCal&lt;br/&gt;(behavioral rules)\"] STRUCT[\"XML / YAML / JSON&lt;br/&gt;(registers, fields,&lt;br/&gt;address maps)\"] end subgraph consumers[\"Downstream Consumers\"] direction TB HUMAN_SPEC[\"Human-Readable Specs&lt;br/&gt;(auto-generated PDF,&lt;br/&gt;Markdown, HTML)\"] WEB_APP[\"Interactive Web Apps&lt;br/&gt;(pre-indexed search,&lt;br/&gt;cross-referenced&lt;br/&gt;register browser)\"] AI_FLOW[\"AI-Augmented Flows&lt;br/&gt;(RTL generation,&lt;br/&gt;testbench synthesis,&lt;br/&gt;assertion extraction)\"] end PDF_OLD -. \"LLM ingestion\" .-&gt; LLM_CONVERT WORD_OLD -. \"LLM ingestion\" .-&gt; LLM_CONVERT PG_OLD -. \"LLM ingestion\" .-&gt; LLM_CONVERT LLM_CONVERT --&gt; MANUAL_REVIEW MANUAL_REVIEW --&gt; RTL_VERIFY RTL_VERIFY -. \"reconciled &amp; validated\" .-&gt; golden golden ==&gt; HUMAN_SPEC golden ==&gt; WEB_APP golden ==&gt; AI_FLOW The thick arrows from the golden source are the steady-state flow: every consumer reads from the same canonical data. The dashed lines on the left represent the one-time migration — the up-front work required to get there. Why Formal Modeling Matters for Fabrics An I/O-memory fabric is governed by rules: ordering constraints, credit protocols, arbitration policies, coherence state transitions, deadlock freedom invariants. These are not well captured by prose. They are well captured by temporal logic. TLA+ (Temporal Logic of Actions) and its procedural alias PlusCal let you express exactly these kinds of rules: “A posted write must not pass a completion with the same requester ID.” “Credits are returned only after the receiver has consumed the corresponding data.” “No reachable state exists in which two agents hold exclusive ownership of the same cache line.” A TLA+ specification is simultaneously: Precise enough for a model checker (TLC) to exhaustively verify. Readable enough for a human to review the intent. Structured enough for an LLM to consume without ambiguity. That last property is the one most teams overlook. When the fabric’s ordering rules live in a formal spec, an LLM generating RTL for an arbiter or a reorder buffer can be given the exact invariants it must satisfy — not a paragraph of English that it might misinterpret. The Migration Path None of this is free. For a team with an existing design, the path looks roughly like this: Step 1 — Convert the existing corpus Take every PDF spec, programmer’s guide, and architecture note and convert it into machine-readable form (structured YAML/JSON for register maps, TLA+ for behavioral rules). This is where LLMs can actually help today. Feed the prose documents into a well-prompted model and let it produce a first-draft structured output. But — and this is critical — every generated artifact must be manually reviewed. LLMs are good at format conversion; they are not reliable at semantic interpretation of ambiguous prose. Step 2 — Verify against the existing RTL The existing RTL is the true golden reference (it is, after all, what the silicon actually does). Use it to validate the converted specs: Run the TLA+ model checker against properties extracted from the RTL. Diff the machine-readable register maps against the RTL’s CSR decoder. Flag every discrepancy — these are either spec bugs, RTL bugs, or both. This step is painful but enormously valuable. Teams that have done it invariably discover long-standing bugs hiding in the gap between the spec and the implementation. Step 3 — Flip the flow Once the golden source is validated, stop editing the PDFs directly. All changes start in the machine-readable source. Human-readable documents, interactive tools, and AI pipelines all consume from the same root. Interactive Specifications A machine-readable golden source enables a class of tooling that PDFs simply cannot support: interactive, pre-indexed, cross-referenced specification browsers. Imagine a web app where an engineer can: Search across all specs simultaneously with structured filters (e.g. “show me every register in the fabric’s credit manager that has a reset value other than zero”). Click a register field and immediately see every ordering rule, every TLA+ invariant, and every testbench sequence that touches it. Get answers in seconds instead of grep-ing through a dozen PDFs. This is not speculative. It is a straightforward engineering project once the data is structured. A Concrete Example: Generated CSR Documentation To make this tangible, I built a Python script that parses a machine-readable register specification (XML-based) and generates a fully self-contained, interactive HTML documentation site — no server, no database, just static files you can open in a browser or host on an internal web server. The golden source is an XML description of every control/status register: address maps, register instances, bit-field definitions, reset values, access policies, and cross-references. The script consumes that XML and produces a set of interlinked HTML pages. Here is what the generated output provides: Global search with pre-built index. At build time, the script constructs a JSON search index covering every register and every bit-field — name, description, address map context — and embeds it directly in the HTML. The search modal (triggered by clicking the floating search button or pressing /) performs instant client-side substring matching against the pre-computed index. Results are categorized with colored chips (Register vs. Bitfield), show context about which address-map instance they belong to, and link directly to the relevant detail section. No server round-trip, no waiting — up to 75 results appear as you type. Filter-as-you-type on every table. Each register summary table has a sticky search bar with a frosted-glass backdrop that filters rows live on every keystroke, matching against any column. On the top-level index page, separate filter inputs cover address-map instances and logical interfaces independently. Visual bit-field diagrams. Every register is rendered as an HTML table where each column is one bit. Three rows show bit numbers (MSB to LSB), default/reset values (0, 1, ?, or —), and field names — with multi-bit fields merged via colspan and labels rotated vertically so they remain readable even in narrow columns. Fields alternate between two blue shades for a zebra-stripe effect; reserved bits are gray; bits beyond the register width are dimmed. Keyboard shortcuts. / opens search, C toggles compact mode (smaller fonts, fewer columns — useful on laptops), S toggles the interface summary panel, T scrolls to top. All suppressed when focus is in an input field. Rich register detail cards. Each register gets its own expandable section with: short and long descriptions, a metadata grid (modules, consumers, access-policy badges), an instances table with computed absolute addresses per interface exposure, the bit-field diagram, and a full bit-field table with access type, reset values, and hardware-load cross-references rendered as dot-separated paths that link to the referenced register. Deep linking with copy-to-clipboard. Every register detail section has a stable URL anchor (name + content hash for uniqueness) and a “Copy link” button that writes the full URL to the clipboard with visual feedback. Engineers can paste direct links into bug reports or chat messages — the recipient lands exactly on the right register, not on page 1 of a 400-page PDF. Compact mode with persistence. The compact toggle shrinks fonts and hides verbose columns (description, address-map name, register width) to fit more registers on screen. The preference is saved to localStorage and restored on next visit. Zero runtime dependencies. The generated HTML files are fully self-contained — CSS and JavaScript are inlined. They can be opened from a file share, served from a minimal web server, or embedded in a CI artifact. No frameworks, no build step, no node_modules. The point is not the specific tool — it is the pattern. Once the register specification lives in a structured, machine-readable format, building this kind of interactive, searchable, deeply-linked documentation is a weekend project. Doing the same thing from a PDF is effectively impossible. The Up-Front Cost and the Payoff Let’s be honest: the up-front work is significant. Converting a mature design’s specification corpus into machine-readable form is a multi-quarter effort, even with LLM assistance. It requires domain experts reviewing every conversion, resolving every ambiguity, and reconciling every spec-vs-RTL discrepancy. The payoff is equally significant: AI-augmented RTL generation becomes viable because the input is unambiguous. Spec-RTL drift becomes structurally impossible — the spec is the input to the toolchain. Onboarding time drops dramatically when new engineers can search and browse instead of reading binders. Bug density decreases because the formal model catches classes of errors (ordering violations, deadlocks, credit leaks) before any RTL is written. The teams that begin this migration now will have a compounding advantage over those that wait. The cost of conversion is fixed; the cost of not converting grows with every generation of AI tooling that could have consumed the spec but couldn’t because it was trapped in a PDF." }, { "title": "Data-Driven Fabric Architecture: Visualizing GPU Traffic Patterns Over PCIe", "url": "/2026/02/22/data-driven-fabric-architecture/", "categories": "Architecture", "tags": "pcie, gpu, fabric, data-analysis, python, visualization", "date": "2026-02-22 10:00:00 -0800", "content": "Architectural decisions for a high-performance I/O-memory fabric should be grounded in data, not gut feel. It sounds obvious, but in practice the pressure to “just pick something reasonable” is real — timelines are tight, the design space is enormous, and canonical answers are rarely published. The antidote is to look at the traffic before committing silicon resources to serve it. Why Data Beats Intuition A fabric connects requesters (CPUs, GPUs, DMA engines) to completers (memory controllers, device BARs, config space). Every design knob — queue depths, arbitration weights, credit pools, virtual-channel allocation — depends on the statistical properties of the workload: Burst length distribution — Are transfers predominantly small (doorbell writes, MMIO) or large (bulk DMA)? Temporal locality — Do requests arrive in steady streams or in bursty clusters separated by idle gaps? Address-space coverage — Is the traffic spread uniformly, or does it hammer a small set of address regions? Correlation between fields — Do payload contents, addresses, and timing carry hidden structure a flat histogram would miss? Getting even one of these wrong can over-provision a path nobody uses or starve the one that matters. A Concrete Example: NVIDIA GPU SM Writes Over PCIe To illustrate the approach, consider a real PCIe trace captured while an NVIDIA H100 GPU executes a streaming-write (SM-initiated) bandwidth test using NVBandwidth. The trace records every TLP on the link — type, address, length, payload, and timestamp — giving a cycle-accurate picture of the traffic the fabric must handle. The Analysis Pipeline The analysis script (analyze_trace_data_animation.py) follows a straightforward pipeline: Load &amp; filter — Read the protocol-analyzer CSV export. Keep only upstream MWr(64) TLPs (the GPU’s posted writes heading toward the host). Parse fields — Extract the payload’s first data word (16-bit, big-endian), the target address bits, and the timestamp. Bucket &amp; window — Divide the trace timeline into 50 equal time bins. For each bin, aggregate over a sliding window of the preceding 10 bins to smooth transient spikes. Group &amp; color — Map the first-word values into 33-element buckets so the histogram bar count stays readable. Each bucket gets a distinct color from a rainbow-gradient palette. Render frames → GIF — Build one HoloViews Bars plot per time bin, export each frame to PNG via headless Chrome (bokeh.io.export_png), then stitch the PNGs into an animated GIF with imageio. The Result The animated histogram below shows how the distribution of first-word values in 2-dword posted writes evolves over the life of the trace. Each colored bar is one 33-value bucket; the y-axis is occurrence count within the sliding window. First-word distribution of 2-DW MWr(64) TLPs, bucketed into groups of 33, animated across 50 time bins (10-bin sliding window). A few things jump out immediately: Non-uniform distribution — The writes are not spread evenly across the value space. Certain buckets dominate, revealing structure in how the SMs organize their write data. Temporal variation — The shape of the histogram shifts over time. Some buckets appear or disappear as the workload progresses, suggesting phased behavior in the GPU’s memory access pattern. Clustering — Adjacent buckets often move together, hinting at spatial locality in the data values the SMs produce. None of these observations are obvious from aggregate statistics alone. The animation makes them visible at a glance. Tools &amp; Stack Component Role pandas / numpy Data loading, filtering, binning HoloViews + Bokeh Declarative plot construction and rendering Selenium + headless Chrome Server-side PNG export of Bokeh figures imageio Animated GIF assembly Python 3 Glue The full script is available in the repository: python-scripts/work/analyze_trace_data_animation.py. Takeaway Before committing transistors to a fabric micro-architecture, capture real traffic, visualize it, and let the data constrain the design space. A one-afternoon analysis script can surface patterns that save months of late-stage re-work — and animated visualizations make those patterns legible to the entire team, not just the person who ran the numbers." }, { "title": "Welcome to schmole.com", "url": "/2026/02/20/welcome/", "categories": "General", "tags": "site, hardware, architecture", "date": "2026-02-20 09:00:00 -0800", "content": "Welcome to schmole.com — a public space for engineering notes, deep dives, and the tools I build while working in silicon hardware architecture. What to expect Architecture &amp; Microarchitecture Trade-off analyses, pipeline design notes, memory system explorations, and write-ups on topics like coherence protocols and on-chip interconnects. RTL &amp; Implementation Notes on synthesis flows, timing constraints, and the gap between architectural intent and physical reality. Performance Engineering Workload characterization, bottleneck hunting, and the cycle-accurate models that reveal what is actually happening inside a chip. Tools &amp; Scripts Python utilities and browser-based tools from the python-scripts and web-apps directories — automation that makes EDA work faster. Stay tuned for more posts." } ]
